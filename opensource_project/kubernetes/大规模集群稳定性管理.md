[TOC]

## 大规模Kubernetes集群稳定性管理

### 稳定性

#### 集群规模

Google Borg 支持 10K+ 数量级的Node节点数量。

Kubernetes v1.6 支持 <=2000

Kubernetes v1.10 支持 <=5000

##### master节点规格

需要由测试得出集群规模与控制节点规格的关系。

#### 拆分etcd存储内容
##### 拆分event

event事件随着集群规模扩大增加较快，而且event的读写都要通过apiserver的访问来达成，这会给apiserver带来较大的访问压力。

将event事件的存储和k8s集群资源状态的存储分别存放在不同的etcd集群服务中，可以大大降低集群资源状态访问的压力，增加集群稳定性。

##### 拆分configmap

configmap存储的内容可能会很大，比如一个应用的配置文件。随着集群规模的扩大，configmap会越来越多，这会给apiserver带来吞吐量的压力。

##### 静态configmap

随着集群规模的扩大，用户为容器应用配置了大量的configmap。kubelet会定时向apiserver发送请求，获得最新的configmap文件，从而对configmap进行remount更新。

据京东统计的apiserver请求数据发现，configmap的相关请求，已经可以占到总请求数的99%以上。这会给apiserver带来巨大访问压力。

#### 容器镜像p2p分发

解决大批量并发下载容器镜像时 harbor 服务压力过大、耗时时间长、成功率低、带宽浪费严重等问题；

后续如果需要使用多地域中心化的 harbor 服务，也可以利用该技术。各个机房仅仅由p2p server从 harbor 下载并缓存镜像。机房内部由p2p server将容器镜像分发给各个Node节点。

#### grpc包升级，解决apiserver不稳定的问题

本节内容参考自京东容器管理平台JDOS2.0：

生产环境中，当集群规模迅速膨胀时，即使利用负载均衡的方式部署kube-apiserver，也常常会出现某个或某几个apiserver不稳定，难以承担访问压力的情况。经过了反复的实验排查，最终确定是grpc的问题导致了apiserver的性能瓶颈。我们对于gRPC包进行了升级，最终地使得apiserver的性能及稳定性都有了大幅度的提升。

[JDOS 2.0：Kubernetes的工业级实践]: http://dockone.io/article/2988
[gRpc异常并夯住的问题分析]: https://bingohuang.com/grpc-error-hung/

#### 宿主机状态判断旁路系统

添加旁路系统的目的是，对Node节点状态变化做二次确认。Node节点notready带来的最大影响就是容器的强制漂移，而依据则完全是kubelet向apiserver上报的状态数据。很多复杂的因素都有可能导致这条通路的不稳定而影响状态更新，从而造成健康Node节点被误诊成故障进而触发漂移，最终导致整个集群雪崩的结果。

#### 集群参数调优和配置

|      | 参数                        | 参考值 | 说明                                                         |
| ---- | --------------------------- | ------ | ------------------------------------------------------------ |
| 1    | apiserver的api-qps          |        | apiserver的qps限制数量                                       |
| 2    | apiserver的api-burst        |        | apiserver峰值请求量设置                                      |
| 3    | kubelet的api-qps            |        | kubelet请求apiserver的qps限制                                |
| 4    | etcd --quota-backend-bytes  |        | 硬盘存储上线（默认2G）                                       |
| 5    | autoscaler 支持 sanity 检查 |        | 在发现要终止集群里超过 50% 的 workers 的时候，放弃这个操作。 |

#### 故障演练与应急恢复

##### etcd的故障恢复

##### apiserver的故障恢复

#### 构建大规模集群参考资料

[网易蜂巢基于万节点kubernetes支撑大规模云应用实践]: http://www.infoq.com/cn/articles/netease-support-large-scale-cloud-app-based-on-kubernetes
[京东大规模Kubernetes集群的精细化运营]: https://dbaplus.cn/news-141-2139-1.html

[DockOne微信分享（一五三）：JDOS 2.0：Kubernetes的工业级实践]: http://dockone.io/article/2988
[深度 | 蚂蚁金服自动化运维大规模 Kubernetes 集群的实践之路]: https://juejin.im/post/5b603ceb6fb9a04f9c43d809

### 自动化运维&运营

#### 服务监控

#####  服务高可用

kube-apiserver、kube-scheduler、kube-controller-manger 使用集群的方式部署；

其他系统服务使用Deployment部署，由k8s集群负责保证指定数量的副本的服务可用性；

##### 集群服务状态实时监控和告警

k8s集群使用prometheus作为监控和告警服务，并提供可视化能力。

##### 集群服务故障恢复

为集群每个服务均需指定故障恢复步骤，并经过演练。

apiserver、kube-scheduler、kube-controller-manager、etcd集群服务故障恢复。

#### 运营与可视化

#### 集群巡检

大规模的运营需要成套的运营工具进行辅助，环节运营人员的工作压力。同时也提供更为自动化的流程，对整个集群提供更为稳固的保障。

##### 巡检工具

**Kubernetes ansible connection plugin**

京东使用的是基于Ansible定制开发的工具，其中集群部署、集群扩展、更新配置、升级代码等操作都有已经定制好的模板。上线时，只需要修改模板中的几个参数就可以完成更新。这样省时省力，十几万物理机规模只需要几个运营人员就可以轻松管理。

#### 压测环境

1. 如何在资源有限的情况下构建或者模拟构建2000+Node节点规模的Kubernetes集群？
2. 环境构建后，压测集群可能存储的瓶颈，重点测试etcd，apiserver，gRPC 。

#### 综上





